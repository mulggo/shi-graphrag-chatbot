#!/usr/bin/env python3
"""
PWRU19RDNE KBì˜ ì›ë³¸ ì†ŒìŠ¤ íŒŒì¼ ì°¾ê¸°
KB ìƒì„± ì „ ì—…ë¡œë“œëœ ì›ë³¸ PDF/ì´ë¯¸ì§€ íŒŒì¼ë“¤
"""

import boto3
import json

def find_kb_data_source():
    """KB ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ ì¡°íšŒ"""
    
    bedrock_agent = boto3.client('bedrock-agent', region_name='us-west-2')
    kb_id = 'PWRU19RDNE'
    
    try:
        # KB ì •ë³´ ì¡°íšŒ
        kb_response = bedrock_agent.get_knowledge_base(knowledgeBaseId=kb_id)
        kb_info = kb_response['knowledgeBase']
        
        print(f"ğŸ“š KB ì •ë³´: {kb_info['name']}")
        print(f"ğŸ“ ì„¤ëª…: {kb_info.get('description', 'N/A')}")
        
        # ë°ì´í„° ì†ŒìŠ¤ ì¡°íšŒ
        ds_response = bedrock_agent.list_data_sources(knowledgeBaseId=kb_id)
        
        print(f"\nğŸ“ ë°ì´í„° ì†ŒìŠ¤ ({len(ds_response['dataSourceSummaries'])}ê°œ):")
        
        for ds in ds_response['dataSourceSummaries']:
            ds_id = ds['dataSourceId']
            ds_name = ds['name']
            
            print(f"\nğŸ” ë°ì´í„° ì†ŒìŠ¤: {ds_name} ({ds_id})")
            
            # ìƒì„¸ ì •ë³´ ì¡°íšŒ
            ds_detail = bedrock_agent.get_data_source(
                knowledgeBaseId=kb_id,
                dataSourceId=ds_id
            )
            
            data_source_config = ds_detail['dataSource']['dataSourceConfiguration']
            s3_config = data_source_config.get('s3Configuration', {})
            
            if s3_config:
                bucket_arn = s3_config.get('bucketArn', '')
                inclusion_prefixes = s3_config.get('inclusionPrefixes', [])
                
                print(f"   ğŸ“¦ S3 ë²„í‚·: {bucket_arn}")
                print(f"   ğŸ“‚ í¬í•¨ ê²½ë¡œ: {inclusion_prefixes}")
                
                # ë²„í‚·ëª… ì¶”ì¶œ
                bucket_name = bucket_arn.split(':')[-1] if bucket_arn else ''
                return bucket_name, inclusion_prefixes
        
        return None, []
        
    except Exception as e:
        print(f"âŒ KB ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None, []

def scan_original_source_files(bucket_name: str, prefixes: list):
    """ì›ë³¸ ì†ŒìŠ¤ íŒŒì¼ ìŠ¤ìº”"""
    
    if not bucket_name:
        print("âŒ ë²„í‚· ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    s3_client = boto3.client('s3', region_name='us-west-2')
    
    print(f"\nğŸ” ì›ë³¸ ì†ŒìŠ¤ íŒŒì¼ ìŠ¤ìº”: s3://{bucket_name}")
    
    try:
        all_files = []
        
        for prefix in prefixes or ['']:
            print(f"\nğŸ“‚ ê²½ë¡œ: {prefix}")
            
            response = s3_client.list_objects_v2(
                Bucket=bucket_name,
                Prefix=prefix,
                MaxKeys=100
            )
            
            files = response.get('Contents', [])
            print(f"   íŒŒì¼ ìˆ˜: {len(files)}ê°œ")
            
            # íŒŒì¼ íƒ€ì…ë³„ ë¶„ë¥˜
            file_types = {}
            sample_files = []
            
            for obj in files:
                key = obj['Key']
                size = obj['Size']
                
                # í™•ì¥ì ì¶”ì¶œ
                if '.' in key:
                    ext = key.split('.')[-1].lower()
                    file_types[ext] = file_types.get(ext, 0) + 1
                
                # ìƒ˜í”Œ ìˆ˜ì§‘
                if len(sample_files) < 5:
                    sample_files.append({
                        'key': key,
                        'size_mb': round(size / 1024 / 1024, 2),
                        'modified': obj['LastModified'].strftime('%Y-%m-%d %H:%M')
                    })
            
            # íŒŒì¼ íƒ€ì… ë¶„í¬
            print(f"   ğŸ“Š íŒŒì¼ íƒ€ì…:")
            for ext, count in sorted(file_types.items()):
                print(f"      .{ext}: {count}ê°œ")
            
            # ìƒ˜í”Œ íŒŒì¼ë“¤
            print(f"   ğŸ“„ ìƒ˜í”Œ íŒŒì¼:")
            for file_info in sample_files:
                print(f"      {file_info['key']} ({file_info['size_mb']} MB, {file_info['modified']})")
            
            all_files.extend(files)
        
        return all_files
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ìŠ¤ìº” ì‹¤íŒ¨: {e}")
        return []

def check_original_file_structure(files: list):
    """ì›ë³¸ íŒŒì¼ êµ¬ì¡° ë¶„ì„"""
    
    print(f"\nğŸ“‹ ì›ë³¸ íŒŒì¼ êµ¬ì¡° ë¶„ì„:")
    
    # PDF íŒŒì¼ë“¤ ì°¾ê¸°
    pdf_files = [f for f in files if f['Key'].lower().endswith('.pdf')]
    image_files = [f for f in files if any(f['Key'].lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png'])]
    
    print(f"ğŸ“š PDF íŒŒì¼: {len(pdf_files)}ê°œ")
    print(f"ğŸ–¼ï¸  ì´ë¯¸ì§€ íŒŒì¼: {len(image_files)}ê°œ")
    
    # PDF íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„
    if pdf_files:
        print(f"\nğŸ“š PDF íŒŒì¼ë“¤:")
        for pdf in pdf_files[:10]:  # ì²˜ìŒ 10ê°œë§Œ
            key = pdf['Key']
            size_mb = round(pdf['Size'] / 1024 / 1024, 2)
            print(f"   {key} ({size_mb} MB)")
    
    return pdf_files, image_files

if __name__ == "__main__":
    print("ğŸ” PWRU19RDNE KB ì›ë³¸ ì†ŒìŠ¤ ì°¾ê¸°\n")
    
    # 1. KB ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ ì¡°íšŒ
    bucket_name, prefixes = find_kb_data_source()
    
    if bucket_name:
        # 2. ì›ë³¸ íŒŒì¼ ìŠ¤ìº”
        files = scan_original_source_files(bucket_name, prefixes)
        
        if files:
            # 3. íŒŒì¼ êµ¬ì¡° ë¶„ì„
            pdf_files, image_files = check_original_file_structure(files)
            
            print(f"\nğŸ’¡ ê²°ë¡ :")
            print(f"   - ì›ë³¸ ì†ŒìŠ¤ ë²„í‚·: s3://{bucket_name}")
            print(f"   - PDF íŒŒì¼: {len(pdf_files)}ê°œ (í˜ì´ì§€ë³„ OCR ì¶”ì¶œ ê°€ëŠ¥)")
            print(f"   - ì´ë¯¸ì§€ íŒŒì¼: {len(image_files)}ê°œ")
        else:
            print("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print("âŒ KB ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")