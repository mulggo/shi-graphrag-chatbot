# GraphRAG Agent 단순화 계획

## 🎯 목표

현재 500+ 줄의 복잡한 GraphRAG Agent를 단순화하면서 핵심 기능 유지

### 핵심 요구사항
1. **지능적 문서 선택**: 필요한 문서를 LLM이 판단 (편향 방지)
2. **관계 기반 추론**: 문서 간 연결점 발견 및 종합
3. **검색 정확도**: Reranking으로 품질 보장
4. **다국어 처리**: 영어로 검색하되 한국어로 답변

## 🤔 핵심 딜레마

### **문제**: LLM 인지 부하 vs 구현 복잡성

**옵션 1: 단일 LLM 호출**
- 장점: 구현 단순
- 단점: LLM이 너무 많은 일을 동시에 처리 (혼란 가능성)

**옵션 2: 다단계 LLM 호출**  
- 장점: 각 단계별 명확한 역할
- 단점: 구현 복잡성, 여러 번 호출

**옵션 3: 기존 구조 정리**
- 장점: 검증된 구조 유지
- 단점: 근본적 단순화 한계

## 📋 현재 상태 분석

### 기존 구조 (복잡)
```
GraphRAG Agent (500+ 줄)
├── Strands Framework
├── 3개 워크플로우 에이전트
│   ├── QueryAnalysisAgent (Lambda: classify_query, extract_entities)
│   ├── RetrievalAgent (Lambda: kb_retrieve)
│   └── SynthesisAgent (LLM 합성)
├── 복잡한 메트릭 시스템
└── 과도한 로깅/추적
```

### 문제점
- Lambda 의존성 (3개 함수)
- Strands 프레임워크 오버헤드
- 복잡한 워크플로우 관리
- 디버깅 어려움

## 🚀 단순화 옵션 비교

### **옵션 A: 기존 구조 유지 + 코드 정리**
```
GraphRAG Agent (200-300줄)
├── 3개 에이전트 유지 (역할 분담)
├── Lambda 제거 → 직접 구현
├── Strands 워크플로우 정리
└── 메트릭/로깅 최소화
```

### **옵션 B: 2단계 단순화**
```
SimpleGraphRAG Agent (150줄)
├── 1단계: 문서 분석 + 검색 (LLM)
└── 2단계: Reranking + 답변 합성 (LLM)
```

### **옵션 C: 완전 단순화**
```
MinimalGraphRAG Agent (100줄)
└── 단일 LLM 호출 (모든 추론 + 도구 사용)
```

## 💡 권장 접근법: 옵션 B (2단계 단순화)

### **이유**:
1. **적절한 인지 부하**: 2번의 LLM 호출로 부담 분산
2. **명확한 역할**: 분석+검색 vs 정제+합성
3. **구현 단순성**: 기존 대비 70% 코드 감소
4. **품질 유지**: 핵심 기능 손실 없음

### **구현 단계**

#### Phase 1: 기존 코드 분석
- [ ] 현재 GraphRAG Agent 백업
- [ ] Lambda 함수 로직 추출
- [ ] 핵심 프롬프트 정리

#### Phase 2: 2단계 Agent 설계
- [ ] Stage 1: 문서 분석 + 다중 검색
- [ ] Stage 2: Reranking + 답변 합성
- [ ] BaseAgent 인터페이스 유지

#### Phase 3: 구현 및 테스트
- [ ] 2단계 워크플로우 구현
- [ ] 기능 테스트 및 품질 검증
- [ ] 성능 비교 (기존 vs 신규)

## 🔧 기술 스택 (옵션 B)

### 제거할 의존성
- ❌ Strands Framework (워크플로우 관리)
- ❌ Lambda 함수 (3개)
- ❌ 복잡한 메트릭 시스템
- ❌ 3개 별도 에이전트

### 유지할 기술
- ✅ AWS Bedrock (LLM + KB 검색)
- ✅ Cohere Reranking
- ✅ BaseAgent 구조
- ✅ 기존 UI 인터페이스
- ✅ 핵심 추론 로직

## 📊 구현 세부사항 (2단계 접근법)

### **Stage 1: 지능적 문서 분석 + 다중 검색**

**목적**: 질문 분석 → 필요한 문서 식별

**입력**: 사용자 질문
**출력**: 필요한 문서 목록 + 이유

**프롬프트 예시**:
```
질문: "{user_question}"

11개 선박 규정 문서:
1. SOLAS Chapter II-2 (화재 안전)
2. FSS Code (고정 소화 시스템)
3. LSA Code (구명 설비)
4. MARPOL (해양 오염 방지)
5. Training Manual (승무원 교육)
6. ... (나머지 문서들)

이 질문에 답하기 위해 어떤 문서들이 필요한가?
각 문서가 왜 필요한지 구체적 이유와 함께 JSON 형식으로 답하라.

형식:
{
  "required_documents": [
    {"name": "SOLAS Chapter II-2", "reason": "화재 감지 및 진압 규정"},
    {"name": "FSS Code", "reason": "고정 소화 시스템 세부 사양"}
  ]
}
```

**LLM 프롬프트**:
```
한국어 질문: "{user_question}"

11개 선박 규정 문서 목록:
[문서 목록...]

작업:
1. 이 한국어 질문에 필요한 문서들을 식별하고 이유를 설명하세요
2. 각 문서별로 영어 검색 키워드를 생성하세요 (문서가 영어로 작성됨)
3. 영어 키워드로 검색을 실행하고 결과를 수집하세요

중요: 검색은 반드시 영어 키워드를 사용하세요. 문서 내용이 영어로 되어 있습니다.

출력 형식:
{
  "analysis": "질문 분석 결과 (한국어)",
  "required_docs": [{"name": "문서명", "reason": "이유 (한국어)", "english_keywords": ["영어 키워드들"]}],
  "search_results": [검색 결과들]
}
```

### **Stage 2: 결과 정제 + 답변 합성**

**LLM 프롬프트**:
```
원본 한국어 질문: "{user_question}"

1단계 영어 검색 결과:
{stage1_results}

작업:
1. 영어 검색 결과를 Cohere Reranking으로 정제하세요
2. 상위 결과들을 관계 기반으로 분석하세요
3. 문서 간 연결점을 찾아 종합적인 한국어 답변을 생성하세요

중요: 
- 검색 결과는 영어 문서이지만, 최종 답변은 반드시 한국어로 작성하세요
- 영어 내용을 정확히 이해하고 자연스러운 한국어로 번역하여 답변하세요

출력 형식:
{
  "reranked_results": [정제된 결과들],
  "relationships": "문서 간 관계 분석 (한국어)",
  "final_answer": "완성된 한국어 답변",
  "references": [참조 정보들]
}
```

### **구현 코드 (약 150줄)**
```python
class SimpleGraphRAGAgent(BaseAgent):
    def process_message(self, message: str, session_id: str) -> Dict:
        # Stage 1: 분석 + 검색
        stage1_result = self._analyze_and_search(message)
        
        # Stage 2: 정제 + 합성
        stage2_result = self._rerank_and_synthesize(message, stage1_result)
        
        return self._format_response(stage2_result)
```

## 🔍 검증 포인트

### 기능 검증
1. **문서 편향 방지**: 필요한 모든 문서에서 검색하는가?
2. **관계 추론**: 문서 간 연결점을 잘 찾는가?
3. **검색 정확도**: Reranking이 품질을 향상시키는가?
4. **답변 완성도**: 종합적이고 실용적인 답변인가?
5. **다국어 처리**: 영어 검색 → 한국어 답변이 정확한가?

### 성능 검증
1. **응답 시간**: 기존 대비 개선되는가?
2. **코드 복잡도**: 150줄 이하 달성하는가?
3. **유지보수성**: 디버깅과 수정이 쉬운가?
4. **안정성**: 에러 처리가 적절한가?

### 품질 검증
1. **일관성**: 같은 질문에 일관된 답변을 하는가?
2. **정확성**: 기존 대비 답변 품질이 유지되는가?
3. **완성도**: 누락되는 정보가 없는가?
4. **사용성**: UI 인터페이스가 정상 작동하는가?

## 📋 체크리스트

### 구현 전 준비
- [ ] 11개 문서 목록 및 특성 파악
- [ ] 기존 Lambda 함수 로직 분석
- [ ] 핵심 프롬프트 템플릿 준비
- [ ] Cohere Reranking API 테스트

### 구현 중 확인사항
- [ ] BaseAgent 인터페이스 준수
- [ ] 에러 처리 및 로깅
- [ ] 설정 파일 호환성
- [ ] UI 컴포넌트 호환성

### 구현 후 검증
- [ ] 기능 테스트 (다양한 질문 유형)
- [ ] 성능 테스트 (응답 시간)
- [ ] 품질 테스트 (답변 비교)
- [ ] 통합 테스트 (전체 시스템)

## 🚨 위험 요소 및 대응

### 위험 요소
1. **LLM 추론 실패**: 문서 분석이 부정확할 수 있음
2. **검색 품질 저하**: Lambda 제거로 인한 품질 하락 가능
3. **성능 저하**: 여러 번의 LLM 호출로 인한 지연
4. **호환성 문제**: 기존 UI와의 인터페이스 불일치

### 대응 방안
1. **프롬프트 최적화**: 명확하고 구체적인 지시사항
2. **점진적 구현**: 단계별 테스트 및 검증
3. **성능 모니터링**: 각 단계별 시간 측정
4. **인터페이스 유지**: 기존 반환 형식 준수

## 📈 성공 기준 (옵션 B)

### 정량적 기준
- 코드 라인 수: 500+ → 150 이하 (70% 감소)
- LLM 호출 횟수: 3개 에이전트 → 2번 호출
- 응답 시간: 기존 대비 유지 또는 개선
- 의존성: Lambda 3개 → 0개

### 정성적 기준
- 답변 품질: 기존 수준 유지 (2단계로 품질 보장)
- 문서 다양성: 편향 문제 해결 (1단계에서 처리)
- 다국어 품질: 영어 검색 정확도 + 한국어 답변 자연스러움
- 유지보수성: 명확한 2단계 구조로 디버깅 용이
- 안정성: 단계별 에러 처리 가능

---

## 🎯 최종 권장사항

**옵션 B (2단계 접근법)를 추천합니다**:

1. **균형잡힌 접근**: 단순성과 품질의 적절한 균형
2. **검증된 로직**: 기존 핵심 기능 유지
3. **구현 용이성**: 명확한 2단계 구조
4. **확장 가능성**: 필요시 단계 추가/수정 용이

**다음 단계**: 이 계획에 동의하시면 구현을 시작하겠습니다.